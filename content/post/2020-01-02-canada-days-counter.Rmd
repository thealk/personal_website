---
title: "Counting Days in Canada: Using ggmap to track time spent in Canada"
author: Thea
date: '2020-01-02'
slug: canada-days-counter
categories:
  - ggplot
  - R
  - personal
tags:
  - ggmap
  - R
  - rstats
  - google maps
header:
  caption: ''
  image: ''
  preview: yes
draft: TRUE
---

```{r, echo = FALSE}
library(emo)
knitr::opts_chunk$set(echo = TRUE, eval=FALSE, fig.align="center")
load('/Users/theaknowles/Documents/GitHub/personal_website/static/project/canada_days_counter.RData')
```

# TL;DR
I used my timeline from Google Maps and the `ggmap` package to count the number of days I have spent in Canada in order to facilitate my Canadian citizenship application.

Disclaimer: Not a geocoder. In fact, ironically, anyone who has spent time with me travelling between any two points can probably attest to the fact that I have absolutely zero geospatial intuition whatsoever. Luckily, that doesn't matter here. What matters more is that there is a whole industry that works with "geographic information systems", and I am not one of those people. Therefore, this information, while functional for this task, is really devoid of any deep knowledge of GIS and the field at large. This is not meant to provide a forray into that arena, merely to demonstrate how I wrangled my own location data to achieve a small goal.

- CODE

# The problem
I am a US citizen, but I have been living in Canada since August 2008. I became a permanent resident of Canada in November 2015. I moved back to the US in August 2019. One of the eligibility requirements for applying for Canadian citizenship is, in addition to being a permanent resident, that you "must have been physically present in Canada for at least 1095 days during the five years before you apply" ([Canada.ca](https://www.canada.ca/en/immigration-refugees-citizenship/services/canadian-citizenship/become-canadian-citizen/eligibility.html#time)). You are required to list all the trips you took that brought you out of the country.
The Canadian government immigration website suggests you use a "travel journal" to document your trips out of Canada. 

I travelled back and forth to the US *all the time*. I am the only member of my family in Canada. When I lived in Montreal, I visited my parents and friends in MA regularly. We took frequent trips to Vermont (mainly to score [Heady Topper](https://alchemistbeer.com/)). When I moved to London, I travelled even more, sometimes heading down to Detroit for just a day or two. My partner moved overseas in 2016, prompting several international trips during my PhD, not to mention conferences, family meet ups, and vacations.

Did I keep a travel journal in careful preparation of my eventual Canadian citizenship application? No, no I did not.

Having been a PR for just over 4 years, and now having no immediate plans to return to Canada, my window of eligibility for citizenship is closing. I need to determine 1) how many days I have spent in Canada so far to ensure I know when my eligibility will likely expire and 2) document my trips.

My cries for help on social media were met with dire responses - there is no easy way around this step. Friends described culling over old emails, Google calendars, passport pages to dtermine exactly when they were in and out of Canada. This sounded miserable and very likely impossible for me, given my frequent back and forths. I needed to figure out a better, faster, more reliable way to document my travels.

# The solution: Location tracking
Every year, Google Maps sends me a cute and slightly creepy summary of all the places I've been - a haunting reminder that, since I never turn my location services off on my phone, which is always with me, Google knows exactly where I am at all times, how long I stay there, and how I travel there (estimated based on speed of transport between locations).

```{r eval = TRUE, echo = FALSE}
blogdown::shortcode('tweet', '1081209086014820352')
```

While that is a bit jarring and worthy of its own ethical debate, in my case for the above problem, it turned out to be EXTREMELY handy. 

Google maps allows you to download your own timeline data in the form of a json file. The [`ggmap`](https://github.com/dkahle/ggmap) package allows you to parse and plot location data. In the end, I was able to parse all of my timeline data since I became a permanent resident[^552], and use it to 1) figure out which days I was in Canada, which would count towards my eligibility requirements, and 2) have a fairly accurate record of the trips I took outside of Canada without having to rely on other sketchy, unreliable forms of documentation (or, god forbid, my MEMORY).

[^552]: Technically if you have been a Canadian PR for less than five years but were living in Canada, you are also allowed to count those days as well. Days spent in Canada before you became a PR within the 5 year time frame count as 0.5 days a piece. In my case, I'm not worrying too much about these days at this point since I have enough days since becoming a PR.

# Steps

[This blog post](https://shiring.github.io/maps/2016/12/30/Standortverlauf_post) gives a nice step-by-step of how to do this. Essentially, the steps are:

## Load libraries

```{r eval = TRUE}
library(jsonlite)
library(ggmap)
library(dplyr)
library(stringr)
library(tidyr)
```

## 0. Get Google API
You need this to be able to use the geocoding functions in ggmap, as well as to be able to plot.

- Need to register for a temporary Google API key
```{r eval = FALSE}
register_google("your-secret-api-key")
```

## 1. Download your location history from your Google Account

- Download your data from [Google takeout](https://takeout.google.com/settings/takeout).
- Be sure to only select "Location History." 
- This can take a little while (it took about 30 minutes for me to download the last 4 years, which is my entire Maps timeline). The final output is a json file called `Location History.json`.
- You can also do this from within [Google Maps](https://www.google.com/maps) by going to "Your Data in Maps" >> "Download your Maps Data"

## 2. Parse the location history file

- This is done using the R package [`jsonlite`](https://cran.r-project.org/web/packages/jsonlite/index.html). I moved my .json output file to my R project folder and ran the following. This also took a couple minutes.

```{r eval=FALSE}
lh <- "Location History.json"
maps_data <- read_json(lh, simplifyVector = TRUE)
```

Extract the location data and convert the time and date into a human-readable format. 
```{r eval=FALSE}
loc <- maps_data$locations
loc$time = as.POSIXct(as.numeric(loc$timestampMs)/1000, origin = "1970-01-01")
```

You can check your earliest and most recent maps data time stamps using `min()` and `max()` functions.
```{r eval = FALSE}
min(loc$time)
max(loc$time)
```


## 3. Tidy the location history
Latitude and longitude are recorded in Google in E7 format. You need to divide the original longitude/latitude values by 10^7 to get standard coordinate formatting.

I also found it helpful to round my final coordinates. The more decimal places you include, the more precise your location identification will be. In my case, all I really cared about was whether I could reliably capture border crossings. Some [light Wikipediaing](https://en.wikipedia.org/wiki/Decimal_degrees) informed me that rounding coordinates to the tens gives you a resolution of 11.1 km, roughly allowing you to distinguish major cities. Zero decimal places, i.e., rounding to the nearest integer, allows for 111.1 km precision, which can unambiguously capture large regions and countries (see also [here](https://gis.stackexchange.com/questions/8650/measuring-accuracy-of-latitude-and-longitude)). Rounding *greatly* reduces the amount of data you have to work with, which speeds things up tremendously. It's also simply not *necessary*, IMHO, at least for this project, to know your location down to 1.11 meters or less. 

To test whether rounding to the nearest integer was sufficient, I made a temp file of 1 days worth of location history on a date that I know I crossed from Ontario to New York. This allowed me to confirm that rounding to 0 decimal places was more or less enough to capture what I wanted, knowing that this may mean I don't capture every single day with 100% accuracy (for example, this runs the risk of days that I spent *near* a border being counted as *crossing* a border - a risk I felt was worth the time saved by the data reduction). To prepare for further reduction, I also added a coordinates column (`coord`).

```{r eval = FALSE}
loc <- loc %>% mutate(
     date = str_sub(time,1,10),
     time = str_sub(time,12,19),
     lon = round((loc$longitudeE7 / 1e7), 0),
     lat = round((loc$latitudeE7 / 1e7), 0),
     coord = paste(lon,lat,sep="_")
) 
```

I grouped the location data by date and coordinates - that is, one row for each unique date-coordinate combination. Since I had rounded my coordinates to 0 decimals earlier, this meant that I got one row for approximately every 111 km. Importantly, I was able to collapse over days that I drove around a single city or over shorter distances. This allowed me to speed up further parsing below.

```{r eval = FALSE}
loc <- loc %>% 
  group_by(date,coord) %>% 
  summarize(n=n()) %>% 
  separate(lonlat, c("lon","lat"), sep="_", remove=FALSE) %>%
  mutate(lon = as.numeric(lon),
         lat = as.numeric(lat)) %>%
  ungroup()
```


At this point, I created a temp file to test one day of travels. You could just as easily a month or specified time span.

```{r eval = FALSE}
tmp_day <- loc %>% 
  filter(date == "2019-10-20") # Look just at Oct 20 2019
tmp_month <- loc %>%
  filter(str_sub(date,1,6)=="2019-10") # Look just at Oct 2019
```

## 4. Coordinates `r emo::ji("point_right")` Country: Reverse geocoding

*Geocoding* allows you to convert addresses into geographic coordiantes.
*Reverse geocoding* allows you to do the opposite: convert coordinates to addresses. 
The `ggmap` package provides a function `revgeocode()` to do just this. Next I created a small function to use `revgeocode()` to get the address from my location data. I then used the `stringr` package to extract the country, which is always the last element of the list produced by `revgeocode()`. This function returns either just the country, or the full address retrieved from Google.

```{r echo=TRUE}
get_country <- function(lon,lat, out=c("country","address")){
  address <- suppressMessages(
    revgeocode(
      as.vector(
        c(as.numeric(lon),
          as.numeric(lat)))))
  # Split address by commas
  address_split <- str_split(address, pattern = ", ")
  # Country is always the last element
  l <- length(address_split[[1]]) 
  country <- address_split[[1]][l]
  
  if(is.na(country)){country <- "NA"}
  if(is.na(address)){address <- "NA"}
    
  if(out=="country"){
    return(country)
  }else if(out=="address"){
    return(address)
  }
}
```

I then created another function to determine, for a given data point, whether I was or was not in a given country (e.g., Canada). This function returns 1 if "country" equals "Canada", and 0 if not. This allows me to sum the days spent in Canada.

```{r}
visited_country <- function(x, country = "Canada"){
  if(x==country){
    visit <- 1
  }else{visit <- 0}
}
```

Next I used `mapply()` to iterate over each observation in my location history data, applying my `get_country()` and `visited_country()` functions to each row.

```{r}
# Get country
loc$country <- mapply(get_country, 
                      loc$lon,loc$lat, 
                      out = "country")
# Get address
loc$address <- mapply(get_country,
                      loc$lon,loc$lat,
                      out = "address")

# Log whether I visited Canada
loc$visited <- mapply(visited_country, 
                      loc$countries, 
                      "Canada")
```

Finally, I computed how many days I was in Canada by grouping my data by date and summing my visits.
```{r}
days_in_canada <- loc %>%
  group_by(date) %>%
  summarize(n_in_canada = sum(visited)) %>%
  ungroup() %>%
  mutate(in_canada = ifelse(n_in_canada > 0,1,0))

sum(days_in_canada$in_canada)
```

# Some odd findings
While for the most part, these points appear to be confirmed by memory and calendar notes, a few oddities arose. According to my maps data, I visited the following countries:

```{r}
unique(loc$countries)
```


One easy-to-fix issue is that, for whatever reason, the US is coded most of the time as "USA" and once as "United States". For my purposes, this doesn't matter, but it probably makes sense to collapse these two:

```{r}
loc <- loc %>%
  mutate(country = ifelse(country=="United States","USA",country))
```


Regarding the other countries I've purportedly "visited", this breakdown isn't 100% accurate. I have never actually visited Thailand or Indonesia. he high number of NAs are a bit worrisome too. 

Closer inspection reveals that most, but not all, of these blips occured on days I was travelling to or around Israel (where my partner was a post-doc for 2 years). I recall Maps having a hard time localizing us sometimes, so perhaps there is something to do with Google's satellite signal or access in this region. To be fair, the Google Maps timeline interface doesn't show these blips, so whatever's happening is getting parsed out by Google Map's final algorithms.

At the end of the day, all I care about is whether it accurately logs whether I was in Canada (even for just a single time point) on a given day. This does seem to be accurate. Even if misses a few days, that's still accurate enough for me at this stage.

# Plotting (optional)
As much as I wish I'd get bonus points from the Canadian government for being able to plot my time in Canada, this is not the case. Practically speaking, then, plotting my maps is just a little additional dopamine rush for me. I *did* want to be able to visually confirm that my coordinates made sense while getting this set up, though, so I've included some basic code for how to do that here. Be it known that there are many other blogs that have much more interesting dataviz tutorials that harness `ggmap` and Google Map timelines, however.

Since I was mostly interested in my presence in Canada in the last five years, during which time I've mostly been in Ontario, we'll plot just that region for now. The `get_map()` function in `ggmap` allows you to download maps of various locations. Deciding the appropriate "zoom" level takes a bit of trial and error and depends on your goals. In this case, 5 works well for seeing the province of Ontario and some surrounding area.

The following maps clearly show the difference between different degrees of coordinate rounding precision.

```{r eval=FALSE}
on <- ggmap::get_map("Ontario", zoom=5)

library(ggplot2)
# Get map for southwestern Ontario
swon <- get_map("Toronto", zoom=5)

ggmap(swon) + 
  geom_point(data = loc, 
             aes(x = lon, y = lat), 
             alpha = 0.5, color = "red")
```

```{r eval=TRUE, echo=FALSE}
map_0_decimals
```



Here's the same map but with coordinates rounded to 2 decimal places instead. Big difference!

```{r echo = FALSE, eval=TRUE}
map_2_decimals
```


# TODO
- list of locations
- how many days in canada?
- mention rebecca




